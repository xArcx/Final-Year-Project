{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzniMBueImrHTx0V6I4NKN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjfEAsIGyixA"
      },
      "outputs": [],
      "source": [
        "\n",
        "#from models.util import load_images\n",
        "#from models.advanced_network import build_advanced_net\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# paths\n",
        "train_dir = '/content/drive/MyDrive/Final Year Proj 21-22/Train/Binary'\n",
        "val_dir = '/content/drive/MyDrive/Final Year Proj 21-22/Validation'\n",
        "test_dir = '/content/drive/MyDrive/Final Year Proj 21-22/Test/Binary'\n",
        "MODEL_DIR = '/content/drive/MyDrive/Final Year Proj 21-22/vit-mnist'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Concatenate\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "#(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "#train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "#test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
        "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
        "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
        "    return imgs / 255.0\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "LEARN_RATE = 0.00001\n",
        "TEST_RATIO = 0.2\n",
        "SEED = 60\n",
        "NUM_CLASSES = 2\n",
        "IMAGE_SIZE=224\n",
        "\n",
        "\n",
        "\n",
        "# augment images using image data generator\n",
        "data_aug = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest',\n",
        "                         shear_range=0.15)\n",
        "## ALEXNET\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(4, 4), activation='relu', input_shape=(224, 224, 1))) \n",
        "model.add(Conv2D(32, kernel_size=(4, 4), activation='relu'))\n",
        "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
        "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
        "model.add(Conv2D(128, (4, 4), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "filepath = \"modelCNN25thDec.h5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n",
        "#                            save_best_only=True, mode='max')\n",
        "\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, \n",
        "#                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "#callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "\n",
        "history_main = model.fit(\n",
        "                    data_aug.flow_from_directory(test_dir,target_size=(224,224), batch_size=BATCH_SIZE, shuffle=True,\n",
        "                         color_mode='grayscale'),\n",
        "                    epochs = 20, \n",
        "                    validation_data=data_aug.flow_from_directory(val_dir,target_size=(224,224), batch_size=BATCH_SIZE, shuffle=True,\n",
        "                         color_mode='grayscale')#,callbacks=callbacks_list\n",
        "                    )\n",
        "# plot loss and accuracy history\n",
        "plt.figure()\n",
        "plt.plot(history_main.history['accuracy'])\n",
        "plt.plot(history_main.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.savefig(MODEL_DIR + '/model_accuracy2.png')\n",
        "plt.figure()\n",
        "plt.plot(history_main.history['loss'])\n",
        "plt.plot(history_main.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "#plt.savefig(MODEL_DIR + '/model_loss2.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "input_ = tf.keras.Input(shape=(224, 224, 1))\n",
        "\n",
        "\n",
        "img_conc=tf.keras.layers.Concatenate()([input_,input_,input_])\n",
        "\n",
        "\n",
        "# Initialize the Pretrained Model\n",
        "feature_extractor = ResNet50(weights='imagenet', \n",
        "                             input_tensor=img_conc,\n",
        "                             include_top=False)\n",
        "\n",
        "# Set this parameter to make sure it's not being trained\n",
        "feature_extractor.trainable = False\n",
        "\n",
        "# Set the input layer\n",
        "\n",
        "\n",
        "\n",
        "x = Conv2D(32,(3,3),activation='relu' ,padding='same')(input_)\n",
        "x = feature_extractor(input_, training=False)\n",
        "# Set the feature extractor layer\n",
        "\n",
        "\n",
        "# Set the pooling layer\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Set the final layer with sigmoid activation function\n",
        "output_ = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model object\n",
        "model = tf.keras.Model(input_, output_)\n",
        "\n",
        "# Compile it\n",
        "model.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Print The Summary of The Model\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "filepath = \"modelCNN25thDec.h5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n",
        "#                            save_best_only=True, mode='max')\n",
        "\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, \n",
        "#                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "#callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "\n",
        "history_main_tf = model.fit(\n",
        "                    data_aug.flow_from_directory(test_dir,target_size=(224,224), batch_size=BATCH_SIZE, shuffle=True,\n",
        "                         color_mode='grayscale'),\n",
        "                    epochs = 20, \n",
        "                    validation_data=data_aug.flow_from_directory(val_dir,target_size=(224,224), batch_size=BATCH_SIZE, shuffle=True,\n",
        "                         color_mode='grayscale')#,callbacks=callbacks_list\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "#2 Transfer learning with VGG16\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "def build_advanced_net(model_weights=None, image_size: int = 224, classes: int = 2) -> Sequential:\n",
        "\n",
        "    conv_base = VGG16(include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      input_shape=(image_size, image_size, 3))\n",
        "    for layer in conv_base.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(conv_base)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "    if model_weights is not None:\n",
        "        model.load_weights(model_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "#3 Transfer learning with vison transformer\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "def build_advanced_net(model_weights=None, image_size: int = 224, classes: int = 2) -> Sequential:\n",
        "\n",
        "    '''conv_base = VGG16(include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      input_shape=(image_size, image_size, 3))'''\n",
        "    \n",
        "    vit_model = vit.vit_b32( image_size = image_size,\n",
        "                                activation = 'softmax',\n",
        "                                pretrained = True,\n",
        "                                include_top = False,\n",
        "                                pretrained_top = False,\n",
        "                                classes=2 )\n",
        "    for layer in vit_model.layers[:-2]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(vit_model)\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "    if model_weights is not None:\n",
        "        model.load_weights(model_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "from vit_keras import visualize\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "\n",
        "vit_model = vit.vit_b32( image_size=224,\n",
        "                                activation = 'softmax',\n",
        "                                pretrained = True,\n",
        "                                include_top = False,\n",
        "                                pretrained_top = False,\n",
        "                                classes = 2)\n",
        "\n",
        "x = load_img('FinalYrProj\\\\Training\\\\Validation\\\\Not Stress\\\\Happy-10.jpg',target_size=(224,224))\n",
        "image = img_to_array(x)\n",
        "#image = image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "\n",
        "\n",
        "attention_map = visualize.attention_map(model = vit_model, image = image)\n",
        "\n",
        "# Plot results\n",
        "fig, (ax1, ax2) = plt.subplots(ncols = 2)\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "ax1.set_title('Original')\n",
        "ax2.set_title('Attention Map')\n",
        "_ = ax1.imshow(x)\n",
        "_ = ax2.imshow(attention_map)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ]
}